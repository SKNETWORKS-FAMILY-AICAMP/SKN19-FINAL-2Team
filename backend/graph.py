# graph.py
import json
import traceback
from langgraph.graph import StateGraph, START, END
from schemas import State
from database import METADATA
from tools import (
    client, 
    safe_json_parse, 
    execute_precise_search, 
    search_notes_vector, 
    search_exact_entity
)

# ëª¨ë¸ ì„¤ì • (ì‹¤ì œ ë°°í¬ ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœìƒìœ„ ëª¨ë¸ë¡œ ë³€ê²½)
MODEL_NAME = "gpt-5.2" 

# ==========================================
# 1. Supervisor (ë¼ìš°í„°)
# ==========================================
def supervisor(state: State) -> State:
    try:
        query = state["user_query"]
        history = state.get("messages", [])
        
        last_ai_msg = ""
        if history and history[-1]["role"] == "assistant":
            last_ai_msg = history[-1]["content"]

        print(f"\nğŸ“¡ [Supervisor] ì…ë ¥: '{query}' (ì´ì „ ì§ˆë¬¸: '{last_ai_msg[:20]}...')")
        
        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í™” íë¦„ì„ ì œì–´í•˜ëŠ” ê´€ë¦¬ìì…ë‹ˆë‹¤.
        
        [ì…ë ¥]
        - ì‚¬ìš©ì ë°œí™”: "{query}"
        - ì´ì „ AI ì§ˆë¬¸: "{last_ai_msg}"
        
        [íŒë‹¨ ê¸°ì¤€]
        1. **interviewer**: ì´ì „ AI ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ê±°ë‚˜ ì •ë³´ê°€ ë„ˆë¬´ ë¶€ì¡±í•œ ê²½ìš°.
        2. **researcher**: êµ¬ì²´ì  ì¶”ì²œ ìš”ì²­ì´ê±°ë‚˜ ì •ë³´ê°€ ì¶©ë¶„í•œ ê²½ìš°.
        3. **writer**: ë‹¨ìˆœ ì¸ì‚¬, ì¡ë‹´.
        
        ì‘ë‹µ(JSON): {{"route": "interviewer" | "researcher" | "writer"}}
        """
        
        msg = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        route = safe_json_parse(msg.choices[0].message.content).get("route", "writer")
        return {"route": route}
        
    except Exception:
        print("\nğŸš¨ [Supervisor Error]")
        traceback.print_exc()
        return {"route": "writer"}

# ==========================================
# 2. Interviewer (ì •ë³´ ìˆ˜ì§‘)
# ==========================================
def interviewer(state: State) -> State:
    try:
        query = state["user_query"]
        current_context = state.get("interview_context", "") or ""
        
        print(f"\nğŸ¤ [Interviewer] ë‹µë³€ ë¶„ì„ ë° ë¬¸ë§¥ ì—…ë°ì´íŠ¸")
        
        extraction_prompt = f"""
        ì‚¬ìš©ì ë‹µë³€ì—ì„œ í–¥ìˆ˜ ì¶”ì²œ ì •ë³´(ê³„ì ˆ, ì„±ë³„, ì·¨í–¥, ì´ë¯¸ì§€ ë“±)ë¥¼ ì¶”ì¶œí•´ ìš”ì•½í•˜ì„¸ìš”.
        - ê¸°ì¡´ ì •ë³´: {current_context}
        - ì‚¬ìš©ì ë‹µë³€: {query}
        í˜•ì‹ ì˜ˆ: "ì„±ë³„: ë‚¨ì„±, ì´ë¯¸ì§€: ì°¨ë„ë‚¨, ê³„ì ˆ: ê²¨ìš¸"
        """
        msg = client.chat.completions.create(
            model="gpt-4o-mini", messages=[{"role": "user", "content": extraction_prompt}]
        )
        updated_context = msg.choices[0].message.content
        print(f"   ğŸ‘‰ ì—…ë°ì´íŠ¸ëœ ì •ë³´: {updated_context}")
        
        judge_prompt = f"""
        ì¶”ì²œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œê°€ìš”? (ìµœì†Œí•œ í–¥ ì·¨í–¥, ë¸Œëœë“œ, ë¶„ìœ„ê¸° ì¤‘ í•˜ë‚˜ ì¡´ì¬)
        ì •ë³´: {updated_context}
        ì‘ë‹µ(JSON): {{"is_sufficient": true/false, "next_question": "ì§ˆë¬¸ ë‚´ìš©"}}
        """
        judge_msg = client.chat.completions.create(
            model="gpt-4o-mini", 
            messages=[{"role": "user", "content": judge_prompt}],
            response_format={"type": "json_object"}
        )
        judge_result = safe_json_parse(judge_msg.choices[0].message.content)
        
        if judge_result.get("is_sufficient"):
            print("   âœ… ì •ë³´ ì¶©ë¶„ -> Researcherë¡œ ì „ë‹¬")
            return {
                "route": "researcher", 
                "interview_context": updated_context,
                "user_query": f"{updated_context} (ì‚¬ìš©ì ì˜ë„ ë°˜ì˜ ì¶”ì²œ)" 
            }
        else:
            print("   â“ ì •ë³´ ë¶€ì¡± -> ì‚¬ìš©ìì—ê²Œ ì¬ì§ˆë¬¸")
            return {
                "route": "end",
                "interview_context": updated_context,
                "final_response": judge_result.get("next_question")
            }
            
    except Exception:
        print("\nğŸš¨ [Interviewer Error]")
        traceback.print_exc()
        return {"route": "writer", "final_response": "ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"}

# ==========================================
# 3. Researcher (ìƒí™©ë³„ ë™ì  ì „ëµ ìˆ˜ë¦½)
# ==========================================
def researcher(state: State) -> State:
    try:
        query = state["user_query"]
        print(f"\nğŸ•µï¸ [Researcher] ìƒí™©ë³„ ë§ì¶¤ ì „ëµ ìˆ˜ë¦½: {query}")

        meta_summary = {k: v[:20] for k, v in METADATA.items()}

        # ğŸ‘‡ [í•µì‹¬ ìˆ˜ì •] 5ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ì˜
        prompt = f"""
        ë‹¹ì‹ ì€ ìµœê³ ì˜ í¼ìŠ¤ë„ í¼í“¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ì ìš”ì²­: "{query}"
        DB ë©”íƒ€ë°ì´í„°: {json.dumps(meta_summary, ensure_ascii=False)}
        
        [ì„ë¬´]
        ì‚¬ìš©ìì˜ ìš”ì²­ ì˜ë„ë¥¼ ë¶„ì„í•˜ê³ , ì•„ë˜ **[ì‹œë‚˜ë¦¬ì˜¤ ë¼ì´ë¸ŒëŸ¬ë¦¬]** ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë¥¼ ê³¨ë¼ 3ê°€ì§€ ê²€ìƒ‰ ì „ëµ(Plan)ì„ ìˆ˜ë¦½í•˜ì„¸ìš”.
        
        === [ì‹œë‚˜ë¦¬ì˜¤ ë¼ì´ë¸ŒëŸ¬ë¦¬] ===
        
        Type A. [ì´ë¯¸ì§€/ë¶„ìœ„ê¸°] (ì˜ˆ: "ì°¨ê°€ìš´ ë„ì‹œ ë‚¨ì", "ì²­ìˆœí•œ ëŠë‚Œ")
        - ì „ëµ 1: **ì§ê´€ì  ì¼ì¹˜** (ì´ë¯¸ì§€ì™€ 100% ë§¤ì¹­ë˜ëŠ” í–¥)
        - ì „ëµ 2: **ë°˜ì „ ë§¤ë ¥** (ì´ë¯¸ì§€ë¥¼ ë³´ì™„í•´ì£¼ëŠ” ë”°ëœ»/ë¶€ë“œëŸ¬ìš´ í–¥)
        - ì „ëµ 3: **ì…ì²´ì  ë§¤ë ¥** (ì²« í–¥ê³¼ ì”í–¥ì´ ë‹¤ë¥¸ ë…íŠ¹í•œ í–¥)
        
        Type B. [íŠ¹ì • í–¥ë£Œ/ë…¸íŠ¸] (ì˜ˆ: "ì¥ë¯¸ í–¥ ì¢‹ì•„í•´", "ìš°ë””í•œ ê±°")
        - ì „ëµ 1: **ë…¸íŠ¸ì˜ ì •ì„** (í•´ë‹¹ ë…¸íŠ¸ê°€ ë©”ì¸ì¸ í–¥ìˆ˜)
        - ì „ëµ 2: **ì¡°í™”ë¡œìš´ ë¸”ë Œë“œ** (í•´ë‹¹ ë…¸íŠ¸ì™€ ê¶í•©ì´ ì¢‹ì€ ë…¸íŠ¸ì™€ì˜ ì¡°í•©)
        - ì „ëµ 3: **ìœ ë‹ˆí¬í•œ í•´ì„** (í•´ë‹¹ ë…¸íŠ¸ë¥¼ ë…íŠ¹í•˜ê²Œ í•´ì„í•œ í–¥ìˆ˜)
        
        Type C. [TPO/ìƒí™©] (ì˜ˆ: "ì†Œê°œíŒ…", "ë°ì¼ë¦¬", "ë©´ì ‘")
        - ì „ëµ 1: **ì‹¤íŒ¨ ì—†ëŠ” ì •ì„** (ê°€ì¥ ëŒ€ì¤‘ì ì´ê³  ì•ˆì „í•œ ì„ íƒ)
        - ì „ëµ 2: **ê°•ë ¬í•œ ì¸ìƒ** (ìƒëŒ€ë°©ì—ê²Œ ê¸°ì–µì— ë‚¨ì„ ë§¤ë ¥ì ì¸ í–¥)
        - ì „ëµ 3: **ê°ê°ì ì¸ ë¶„ìœ„ê¸°** (ì€ì€í•˜ê²Œ ë¶„ìœ„ê¸°ë¥¼ ë”í•´ì£¼ëŠ” í–¥)
        
        Type D. [ìœ ì‚¬ í–¥ìˆ˜ ì°¾ê¸°] (ì˜ˆ: "ìƒ¤ë„¬ ë„˜ë²„5 ê°™ì€ ê±°", "ì¡°ë§ë¡  ë¹„ìŠ·í•œ ê±°")
        - ì „ëµ 1: **DNA ì¼ì¹˜** (ë©”ì¸ ë…¸íŠ¸ì™€ êµ¬ì¡°ê°€ ê°€ì¥ ìœ ì‚¬í•œ í–¥)
        - ì „ëµ 2: **í˜„ëŒ€ì  í•´ì„** (ë¹„ìŠ·í•˜ì§€ë§Œ ë” íŠ¸ë Œë””í•˜ê±°ë‚˜ ëª¨ë˜í•œ ëŠë‚Œ)
        - ì „ëµ 3: **ë‹¤ë¥¸ ê³„ì ˆê°** (ë¹„ìŠ·í•œ ëŠë‚Œì´ì§€ë§Œ ë” ê°€ë³ê±°ë‚˜/ë¬´ê±°ìš´ ë²„ì „)
        
        Type E. [ì„ ë¬¼/ì…ë¬¸/ì •ë³´ë¶€ì¡±] (ì˜ˆ: "ì—¬ì¹œ ì„ ë¬¼", "ì…ë¬¸ìš©")
        - ì „ëµ 1: **í˜¸ë¶ˆí˜¸ ì—†ëŠ” ë² ìŠ¤íŠ¸** (ëŒ€ì¤‘ì„± 1ìœ„, ì‹¤íŒ¨ í™•ë¥  0%)
        - ì „ëµ 2: **íŠ¸ë Œë””í•œ ìœ í–‰** (ìš”ì¦˜ ê°€ì¥ í•«í•œ ë¸Œëœë“œë‚˜ í–¥)
        - ì „ëµ 3: **ì„¸ë ¨ëœ ë‹ˆì¹˜** (í”í•˜ì§€ ì•Šê³  ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ì„ ë¬¼)
        
        === [ì‘ì„± ê·œì¹™] ===
        1. ìœ„ ì‹œë‚˜ë¦¬ì˜¤ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ 3ê°œì˜ Planì„ ì‘ì„±í•˜ì„¸ìš”.
        2. **strategy_name**ì€ ìœ„ì—ì„œ ì •ì˜í•œ ì „ëµ ì´ë¦„(ì˜ˆ: "ì§ê´€ì  ì¼ì¹˜")ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
        3. **í•„ìˆ˜**: ë…¸íŠ¸(Note) í‚¤ì›Œë“œëŠ” ë°˜ë“œì‹œ **ì˜ì–´(English)**ë¡œ ë³€í™˜í•˜ì„¸ìš”. (ì¥ë¯¸->Rose)
        4. ì¶”ìƒì  í‘œí˜„ì€ 'use_vector_search': trueë¡œ ì„¤ì •í•˜ì„¸ìš”.
        
        ì‘ë‹µ(JSON) ì˜ˆì‹œ:
        {{
            "scenario_type": "Type A",
            "plans": [
                {{
                    "priority": 1,
                    "strategy_name": "ì§ê´€ì  ì¼ì¹˜",
                    "filters": [],
                    "note_keywords": ["Mint", "Aquatic"],
                    "use_vector_search": true
                }},
                ... (ì´ 3ê°œ)
            ]
        }}
        """
        
        msg = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        
        parsed = safe_json_parse(msg.choices[0].message.content)
        plans = parsed.get("plans", []) if parsed else []
        scenario_type = parsed.get("scenario_type", "Unknown")
        
        print(f"   ğŸ’¡ ì„ íƒëœ ì‹œë‚˜ë¦¬ì˜¤: {scenario_type}")
        
        search_logs = []
        final_result_text = ""
        
        for plan in plans:
            strategy = plan.get('strategy_name', f"Strategy-{plan.get('priority')}")
            print(f"   ğŸ‘‰ ì‹¤í–‰: {strategy}")
            
            # í•„í„° ì¡°ë¦½
            current_filters = []
            for f in plan.get("filters", []):
                col = f.get('column')
                val = f.get('value')
                if not col or not val: continue
                
                if col in ['brand', 'perfume_name']:
                    corrected = search_exact_entity(val, col)
                    if corrected: f['value'] = corrected
                current_filters.append(f)
            
            notes = []
            if plan.get("use_vector_search"):
                notes.extend(search_notes_vector(query, top_k=3))
            
            for k in plan.get("note_keywords", []):
                notes.extend(search_notes_vector(k, top_k=2))
                
            if notes:
                current_filters.append({"column": "note", "value": list(set(notes))})
            
            # ê²€ìƒ‰ ì‹¤í–‰
            result_text = execute_precise_search(current_filters)
            
            if result_text:
                print(f"     âœ… ê²°ê³¼ í™•ë³´")
                search_logs.append(f"ì „ëµ [{strategy}] ì„±ê³µ")
                # ê²°ê³¼ í…ìŠ¤íŠ¸ì— ì „ëµ ì´ë¦„ì„ ë¶™ì—¬ì„œ Writerê°€ êµ¬ë¶„í•  ìˆ˜ ìˆê²Œ í•¨
                final_result_text += f"\n=== [ì „ëµ: {strategy}] ===\n{result_text}\n"
            else:
                print(f"     âŒ ê²°ê³¼ ì—†ìŒ")
                search_logs.append(f"ì „ëµ [{strategy}] ê²°ê³¼ ì—†ìŒ")
        
        if not final_result_text:
            final_result_text = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        return {
            "search_plans": plans,
            "search_logs": search_logs,
            "research_result": final_result_text,
            "route": "writer"
        }
        
    except Exception:
        print("\nğŸš¨ [Researcher Error]")
        traceback.print_exc()
        return {"research_result": "ì˜¤ë¥˜ ë°œìƒ", "route": "writer"}


# ==========================================
# 4. Writer (ë™ì  ì „ëµ ë°˜ì˜ ìŠ¤í† ë¦¬í…”ë§)
# ==========================================
# graph.py

def writer(state: State) -> State:
    try:
        print("âœï¸ [Writer] ë‹µë³€ ì‘ì„±")
        query = state["user_query"]
        result = state.get("research_result", "")
        
        # ğŸ‘‡ [ìˆ˜ì •ë¨] HTML íƒœê·¸ ë°©ì‹ í¬ê¸° -> í‘œì¤€ ë§ˆí¬ë‹¤ìš´ ë°©ì‹ ì‚¬ìš©
        # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ ê°€ì¥ ì•ˆì „í•œ ë°©ë²•ì„ ì„ íƒí•©ë‹ˆë‹¤.
        
        prompt = f"""
        ë‹¹ì‹ ì€ í–¥ìˆ˜ë¥¼ ì˜ ëª¨ë¥´ëŠ” ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¸ìƒì—ì„œ ê°€ì¥ ì¹œì ˆí•œ í–¥ìˆ˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
        
        [ì‚¬ìš©ì ìš”ì²­]: "{query}"
        
        [ê²€ìƒ‰ëœ í–¥ìˆ˜ ë°ì´í„°]: 
        {result}
        
        [ì‘ì„± ê·œì¹™ - í•„ë…]
        1. **ëª©ì°¨ êµ¬ì„±**: ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ëµ ì´ë¦„(ì˜ˆ: 'ì§ê´€ì  ì¼ì¹˜' ë“±)ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
        
        2. **ì´ë¯¸ì§€ í•„ìˆ˜ (í‘œì¤€ ë§ˆí¬ë‹¤ìš´)**: 
           - ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ì§€í‚¤ì„¸ìš”.
           - `![í–¥ìˆ˜ëª…](ì´ë¯¸ì§€ë§í¬)`
           - ì˜ˆ: `![Chanel No.5](https://...)`
        
        3. **[ë§¤ìš° ì¤‘ìš”] ì „ë¬¸ ìš©ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ ğŸš«**:
           - **ê¸ˆì§€ì–´**: ë…¸íŠ¸(Note), ì–´ì½”ë“œ(Accord), íƒ‘/ë¯¸ë“¤/ë² ì´ìŠ¤, ìš°ë””, ìŠ¤íŒŒì´ì‹œ, ì‹œíŠ¸ëŸ¬ìŠ¤, í”Œë¡œëŸ´, ë¨¸ìŠ¤í¬, ì‹œí”„ë ˆ, í‘¸ì œë¥´, ì˜¤ë¦¬ì—”íƒˆ ë“±.
           - **ë²ˆì—­ ì§€ì¹¨**: ë¬´ì¡°ê±´ ì˜¤ê°ì´ ëŠê»´ì§€ëŠ” **ì‰¬ìš´ ìš°ë¦¬ë§**ë¡œ í’€ì–´ì„œ ì“°ì„¸ìš”.
             - ìš°ë”” -> ë¹„ì— ì –ì€ ìˆ²ì† ë‚˜ë¬´ ëƒ„ìƒˆ, ì˜¤ë˜ëœ ì¢…ì´ ëƒ„ìƒˆ
             - ìŠ¤íŒŒì´ì‹œ -> ì½”ëì´ ì°¡í•œ í›„ì¶” ëŠë‚Œ, í†¡ ì˜ëŠ” ë§¤ë ¥
             - ì‹œíŠ¸ëŸ¬ìŠ¤ -> ê°“ ì§  ë ˆëª¬ì˜ ìƒí¼í•¨, ê·¤ê»ì§ˆ ê¹” ë•Œ ë‚˜ëŠ” í–¥
             - ë¨¸ìŠ¤í¬ -> í¬ê·¼í•œ ì‚´ê²° ëƒ„ìƒˆ, ë½€ì†¡ë½€ì†¡í•œ ì´ë¶ˆ ëƒ„ìƒˆ
             - ë ˆë”ë¦¬ -> ìƒˆ ê°€ì£½ ì¬í‚·ì—ì„œ ë‚˜ëŠ” ë¬µì§í•œ ëƒ„ìƒˆ
             - í”Œë¡œëŸ´ -> ê½ƒì§‘ì— ë“¤ì–´ê°”ì„ ë•Œ ë‚˜ëŠ” ìƒí™” í–¥ê¸°

        4. **ì •ë³´ í‘œê¸°**: ë¸Œëœë“œ, ì´ë¦„, ì¶œì‹œë…„ë„, ì¡°í–¥ì‚¬ ì •ë³´ëŠ” í•˜ë‹¨ì— ê¹”ë”í•˜ê²Œ ì ìœ¼ì„¸ìš”.
        
        [ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
        
        ì•ˆë…•í•˜ì„¸ìš”! [ì´ë¯¸ì§€/ìš”ì²­]ì— ë”± ë§ëŠ” í–¥ìˆ˜ 3ê°€ì§€ë¥¼ ê³¨ë¼ë´¤ì–´ìš”.
        
        ### 1. [ì „ëµì´ë¦„] **ë¸Œëœë“œ - í–¥ìˆ˜ëª…**
        ![í–¥ìˆ˜ì´ë¯¸ì§€](ë§í¬)
        
        - **ì–´ë–¤ í–¥ì¸ê°€ìš”?**: í†¡ ì˜ëŠ” ë ˆëª¬ í–¥ìœ¼ë¡œ ì‹œì‘í•´ì„œ, ì‹œê°„ì´ ì§€ë‚˜ë©´ ë¹„ ì˜¨ ë’¤ ìˆ²ì†ì— ìˆëŠ” ë“¯í•œ ì°¨ë¶„í•œ ë‚˜ë¬´ ëƒ„ìƒˆê°€ ë‚¨ì•„ìš”.
        - **ì¶”ì²œ ì´ìœ **: ì°¨ê°€ìš´ ë„ì‹œ ë‚¨ìì˜ ì´ë¯¸ì§€ë¥¼ ì™„ì„±ì‹œì¼œ ì¤„ ì„¸ë ¨ëœ í–¥ì´ì—ìš”.
        - **ì •ë³´**: 2023ë…„ ì¶œì‹œ / ì¡°í–¥ì‚¬ OOO
        
        ... (ë‚˜ë¨¸ì§€ ë™ì¼)
        """
        
        msg = client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "user", "content": prompt}]
        )
        return {"final_response": msg.choices[0].message.content}
    except Exception:
        print("\nğŸš¨ [Writer Error]")
        traceback.print_exc()
        return {"final_response": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}


# ==========================================
# Graph Build
# ==========================================
def build_graph():
    graph = StateGraph(State)
    
    graph.add_node("supervisor", supervisor)
    graph.add_node("interviewer", interviewer)
    graph.add_node("researcher", researcher)
    graph.add_node("writer", writer)
    
    graph.add_edge(START, "supervisor")
    
    def route_decision(state: State):
        return state["route"]
    
    graph.add_conditional_edges(
        "supervisor",
        route_decision,
        {"interviewer": "interviewer", "researcher": "researcher", "writer": "writer"}
    )
    
    graph.add_conditional_edges(
        "interviewer",
        route_decision,
        {"researcher": "researcher", "end": END}
    )
    
    graph.add_edge("researcher", "writer")
    graph.add_edge("writer", END)
    
    return graph.compile()