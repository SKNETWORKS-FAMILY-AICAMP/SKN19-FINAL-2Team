# ====== [ksu] í…ŒìŠ¤í„° ==========
import os
import time  # [ì¶”ê°€] time ëª¨ë“ˆ ì„í¬íŠ¸
from datetime import datetime
# ============================

import json
import traceback
import re
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver 
from schemas import State
from database import METADATA
from tools import (
    client, 
    safe_json_parse, 
    execute_precise_search, 
    search_notes_vector, 
    search_exact_entity
)

# ==========================================
# âš™ï¸ ëª¨ë¸ ì„¤ì •
# ==========================================
FAST_MODEL = "gpt-4o"
HIGH_PERFORMANCE_MODEL = "gpt-5.2" 

# ==========================================
# 1. Supervisor (ë¼ìš°í„°)
# ==========================================


# graph.py ì˜ supervisor í•¨ìˆ˜ êµì²´

def supervisor(state: State) -> State:
    try:
        query = state["user_query"]

        # ============================== [ksu] í…ŒìŠ¤í„° =============================
        test_info = None
        # [ğŸ‘‡ /t ëª…ë ¹ì–´ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€ë¨]
        if query.startswith("/t"):
            try:
                # ì˜ˆ: /t [ëª©ì ],[ì‹œë‚˜ë¦¬ì˜¤],[ê¸°ëŒ€ê°’] ì‹¤ì œì§ˆë¬¸
                # meta_part, real_query = query.split("]", 1)
                # meta_part = meta_part.replace("/t", "").replace("[", "").strip()
                # real_query = real_query.strip()
                
                # parts = [p.strip() for p in meta_part.split(",")]
                # if len(parts) >= 3:
                # ì •ê·œì‹ìœ¼ë¡œ ëŒ€ê´„í˜¸ [...] ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ
                # ì˜ˆ: /t [ëª©ì ],[ì‹œë‚˜ë¦¬ì˜¤],[ê¸°ëŒ€ê°’] ì§ˆë¬¸ -> ['ëª©ì ', 'ì‹œë‚˜ë¦¬ì˜¤', 'ê¸°ëŒ€ê°’']
                matches = re.findall(r"\[(.*?)\]", query)
                
                if len(matches) >= 3:
                    test_info = {
                        # "purpose": parts[0],
                        # "scenario": parts[1],
                        # "expected": parts[2]
                        "purpose": matches[0].strip(),
                        "scenario": matches[1].strip(),
                        "expected": matches[2].strip(),
                        "start_time": time.time() 
                    }
                    # query = real_query
                    # [ì¤‘ìš”] ì‹¤ì œ ì§ˆë¬¸ ì¶”ì¶œ (ë§ˆì§€ë§‰ ']' ì´í›„ì˜ ëª¨ë“  í…ìŠ¤íŠ¸)
                    last_bracket_idx = query.rfind("]")
                    if last_bracket_idx != -1:
                        query = query[last_bracket_idx+1:].strip()
                        
                    print(f"ğŸ§ª [Test Mode] {test_info}", flush=True)
            except Exception:
                # pass
                print("âš ï¸ íŒŒì‹± ì—ëŸ¬ ë°œìƒ", flush=True)
        # ============================== [ksu] í…ŒìŠ¤í„° =============================
        
        print(f"\nğŸ“¡ [Supervisor] ì…ë ¥: '{query}'", flush=True)
        
        prompt = f"""
        ë‹¹ì‹ ì€ ëŒ€í™” íë¦„ì„ ì œì–´í•˜ëŠ” ê´€ë¦¬ìì…ë‹ˆë‹¤.
        
        [ì…ë ¥]
        - ì‚¬ìš©ì ë°œí™”: "{query}"
        
        [íŒë‹¨ ê¸°ì¤€]
        1. **researcher (ì¦‰ì‹œ ê²€ìƒ‰)**:
           - **[ì£¼ì˜]** ë¬¸ë§¥ ì—†ì´ë„ ê²€ìƒ‰ ê°€ëŠ¥í•œ **ì™„ë²½í•œ ìš”ì²­**ì¼ ë•Œë§Œ ì„ íƒí•˜ì„¸ìš”.
           - ì˜ˆ: "ì¡°ë§ë¡ ì˜ ìš°ë””í•œ í–¥ìˆ˜ ì¶”ì²œí•´ì¤˜", "20ëŒ€ ì—¬ìê°€ ì“¸ ì¥ë¯¸í–¥ í–¥ìˆ˜"
           
        2. **interviewer (ë¬¸ë§¥ ì—…ë°ì´íŠ¸ ë° ì§ˆë¬¸)**:
           - **ëŒ€ë¶€ë¶„ì˜ ê²½ìš°ëŠ” ì´ê³³ì…ë‹ˆë‹¤.**
           - **ì§§ì€ ë‹µë³€/ì†ì„±**: "ê·€ì—¬ìš´ í¸ì´ì•¼", "ì‹œí¬í•´", "ìš°ë””í•œ ê±°", "20ëŒ€" ë“± ì‚¬ìš©ìì˜ ì·¨í–¥ì´ë‚˜ íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì„ íƒí•˜ì„¸ìš”.
           - **ë¶ˆì™„ì „í•œ ìš”ì²­**: "ì¡°ë§ë¡  ì¶”ì²œí•´ì¤˜" (ì–´ë–¤ í–¥?)
           - **ì´ìœ **: ì´ì „ ëŒ€í™”ì˜ ë¬¸ë§¥(Brand ë“±)ê³¼ í•©ì¹˜ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤.
           
        3. **writer (ì¡ë‹´/ì¢…ë£Œ)**:
           - í–¥ìˆ˜ì™€ ì „í˜€ ìƒê´€ì—†ëŠ” ì¸ì‚¬("ì•ˆë…•"), ì‹œìŠ¤í…œ ë¶ˆë§Œ, ì¢…ë£Œ ìš”ì²­.
           - **[ì¤‘ìš”] ì• ë§¤í•˜ë©´ ë¬´ì¡°ê±´ 'interviewer'ë¡œ ë³´ë‚´ì„¸ìš”.**
        
        ì‘ë‹µ(JSON): {{"route": "interviewer" | "researcher" | "writer"}}
        """
        
        msg = client.chat.completions.create(
            model=FAST_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )

        # ============== [ksu] í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„ =================
        in_tok = msg.usage.prompt_tokens
        out_tok = msg.usage.completion_tokens
        current_in = state.get("input_tokens", 0) + in_tok
        current_out = state.get("output_tokens", 0) + out_tok
        # ===================================================

        route = safe_json_parse(msg.choices[0].message.content).get("route", "writer")
        
        print(f"   ğŸš¦ ê²°ì •ëœ ê²½ë¡œ: {route}", flush=True)

        # ============== [ksu] í† í° ì •ë³´ë„ í•¨ê»˜ ë¦¬í„´ =================
        # return {"route": route}
        return {"route": route,
                "input_tokens": current_in,
                "output_tokens": current_out,
                "user_query": query,            # [í…ŒìŠ¤í„°] íŒŒì‹±ëœ ì‹¤ì œ ì§ˆë¬¸
                "test_info": test_info}         # [í…ŒìŠ¤í„°] í…ŒìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„°
        # =======================================================
        
    except Exception:
        print("\nğŸš¨ [Supervisor Error]", flush=True)
        traceback.print_exc()
        return {"route": "writer"}
    
    
def interviewer(state: State) -> State:
    try:
        query = state["user_query"]
        current_context = state.get("interview_context", "") or ""
        
        print(f"\nğŸ¤ [Interviewer] ë‹µë³€ ë¶„ì„ ë° ë¬¸ë§¥ ì—…ë°ì´íŠ¸", flush=True)
        
        # 1. ì •ë³´ ì¶”ì¶œ (ì´ë¯¸ì§€/ë¶„ìœ„ê¸° ê°•ì¡°)
        extraction_prompt = f"""
        ì‚¬ìš©ì ë‹µë³€ì—ì„œ í–¥ìˆ˜ ì¶”ì²œ ì •ë³´ë¥¼ ìˆëŠ” ê·¸ëŒ€ë¡œ ìš”ì•½í•˜ì„¸ìš”.
        
        [í•µì‹¬ ì§€ì¹¨]
        1. **ì´ë¯¸ì§€/ë¶„ìœ„ê¸° í¬ì°©**: ì‚¬ìš©ìê°€ 'í–¥'ì„ ëª°ë¼ë„ 'ì´ë¯¸ì§€(ì‹œí¬, ì°¨ê°€ì›€, ëŸ¬ë¸”ë¦¬ ë“±)'ë¥¼ ë§í–ˆìœ¼ë©´ ë°˜ë“œì‹œ ê¸°ë¡í•˜ì„¸ìš”.
        2. **íŒ©íŠ¸ ì²´í¬**: ì‚¬ìš©ìì˜ ì…ë ¥ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•´ì„œ ì ì§€ ë§ˆì„¸ìš”.
        3. **í˜•ì‹**: "ë¸Œëœë“œ: OOO, ì´ë¯¸ì§€: OOO, ì·¨í–¥: ì •ë³´ ì—†ìŒ, ëŒ€ìƒ: OOO"
        
        - ê¸°ì¡´ ì •ë³´: {current_context}
        - ì‚¬ìš©ì ë‹µë³€: {query}
        """
        msg = client.chat.completions.create(
            model=FAST_MODEL,
            messages=[{"role": "user", "content": extraction_prompt}]
        )

        # ================= [ksu] 1ì°¨ í† í° ì§‘ê³„ ======================
        in_tok1 = msg.usage.prompt_tokens
        out_tok1 = msg.usage.completion_tokens
        # =========================================================

        updated_context = msg.choices[0].message.content
        print(f"   ğŸ‘‰ ì—…ë°ì´íŠ¸ëœ ì •ë³´: {updated_context}", flush=True)
        
        # 2. íŒë‹¨ ë° ì§ˆë¬¸ ìƒì„± (ìœ ì—°í•œ íŒë‹¨ & ë…¼ë¦¬ì  ì§ˆë¬¸)
        judge_prompt = f"""
        í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì¶”ì²œ ê²€ìƒ‰ì„ ì‹œì‘í•˜ê¸°ì— ì¶©ë¶„í•œì§€ íŒë‹¨í•˜ì„¸ìš”.
        
        [íŒë‹¨ ê¸°ì¤€ - ìœ ì—°í•¨]
        1. **ì¶©ë¶„í•¨(true)**: 
           - êµ¬ì²´ì ì¸ 'í–¥(Note)'ì„ ëª°ë¼ë„, **ëª…í™•í•œ 'ì´ë¯¸ì§€/ë¶„ìœ„ê¸°'(ì˜ˆ: ì‹œí¬, ì°¨ê°€ì›€, ë„ë„í•¨)**ê°€ ìˆë‹¤ë©´ **ì¶©ë¶„**í•˜ë‹¤ê³  íŒë‹¨í•˜ì„¸ìš”. (Researcherê°€ ì´ë¯¸ì§€ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•¨)
           - ë¸Œëœë“œì™€ ëŒ€ìƒë§Œ ìˆê³  ì•„ë¬´ëŸ° íŒíŠ¸ê°€ ì—†ì„ ë•Œë§Œ 'ë¶ˆì¶©ë¶„'ì…ë‹ˆë‹¤.
           
        2. **ë¶€ì¡±í•¨(false)**: 
           - ì •ë§ ì•„ë¬´ëŸ° ë‹¨ì„œ(í–¥ë„ ëª¨ë¥´ê³  ì´ë¯¸ì§€ë„ ë§ ì•ˆ í•¨)ê°€ ì—†ì„ ë•Œ.
        
        [â˜…ì§ˆë¬¸ ì‘ì„± ê°€ì´ë“œ - ë¬¸ë§¥ ìœ ì§€ (Context Awareness)â˜…]
        ë§Œì•½ ì§ˆë¬¸ì´ í•„ìš”í•˜ë‹¤ë©´, **ì‚¬ìš©ìê°€ ë°©ê¸ˆ í•œ ë§**ì„ ë°˜ì˜í•´ì„œ ë¬¼ì–´ë³´ì„¸ìš”. (ë™ë¬¸ì„œë‹µ ê¸ˆì§€)
        
        **Case A. ì‚¬ìš©ìê°€ 'ì°¨ê°€ìš´/ì‹œí¬í•œ' ì´ë¯¸ì§€ë¥¼ ì–¸ê¸‰í–ˆëŠ”ë° ëª¨í˜¸í•  ë•Œ:**
        - (ë‚˜ìœ ì˜ˆ): "ë”°ëœ»í•œ ì»¤í”¼ í–¥ì€ ì–´ë– ì„¸ìš”?" (ì‚¬ìš©ì ë§ ë¬´ì‹œ)
        - (ì¢‹ì€ ì˜ˆ): "**ì°¨ê°€ìš´ ì´ë¯¸ì§€**ë¼ê³  í•˜ì…¨êµ°ìš”! êµ¬ì²´ì ìœ¼ë¡œ **ë„ì‹œì ì´ê³  ë‚ ì¹´ë¡œìš´ ì°¨ê°€ì›€(ëª¨ë˜)**ì¸ê°€ìš”, ì•„ë‹ˆë©´ **ìƒˆë²½ ìˆ²ì† ê°™ì€ ì„œëŠ˜í•œ ì°¨ê°€ì›€(ìš°ë””)**ì¸ê°€ìš”?"
        
        **Case B. ì „í˜€ ì •ë³´ê°€ ì—†ì„ ë•Œ:**
        - "í‰ì†Œ ê·¸ë¶„ì˜ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ì´ë‚˜ ë¶„ìœ„ê¸°ê°€ ì–´ë–¤ê°€ìš”? (ì˜ˆ: ê·€ì—¬ìš´ í¸, ì‹œí¬í•œ í¸)"
        
        ì •ë³´: {updated_context}
        
        ì‘ë‹µ(JSON): 
        {{
            "is_sufficient": true/false, 
            "next_question": "ìƒì„±ëœ ì§ˆë¬¸ ë‚´ìš©"
        }}
        """
        judge_msg = client.chat.completions.create(
            model=FAST_MODEL,
            messages=[{"role": "user", "content": judge_prompt}],
            response_format={"type": "json_object"}
        )

        # ========================= [ksu] 2ì°¨ í† í° ì§‘ê³„ ë° ìµœì¢… í•©ì‚° =========================
        in_tok2 = judge_msg.usage.prompt_tokens
        out_tok2 = judge_msg.usage.completion_tokens
        
        total_in = state.get("input_tokens", 0) + in_tok1 + in_tok2
        total_out = state.get("output_tokens", 0) + out_tok1 + out_tok2
        # ===============================================================================

        judge_result = safe_json_parse(judge_msg.choices[0].message.content)
        
        if judge_result.get("is_sufficient"):
            print("   âœ… ì •ë³´ ì¶©ë¶„(ì´ë¯¸ì§€/ì·¨í–¥ í¬í•¨ë¨) -> Researcherë¡œ ì „ë‹¬", flush=True)
            return {
                "route": "researcher", 
                "interview_context": updated_context,
                "user_query": f"{updated_context} (ì‚¬ìš©ì ì˜ë„ ë°˜ì˜)", 
                "input_tokens": total_in, # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
                "output_tokens": total_out # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
            }
        else:
            print("   â“ ì •ë³´ ë¶€ì¡± -> ì‚¬ìš©ìì—ê²Œ ì¬ì§ˆë¬¸", flush=True)
            return {
                "route": "end",
                "interview_context": updated_context,
                "final_response": judge_result.get("next_question"),
                "input_tokens": total_in, # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
                "output_tokens": total_out # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
            }
            
    except Exception:
        print("\nğŸš¨ [Interviewer Error]", flush=True)
        traceback.print_exc()
        return {"route": "writer", "final_response": "ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"}

# ==========================================
# 3. Researcher (ì „ëµ ìˆ˜ë¦½) - ì˜ë„ ì¤‘ì‹¬ ì „ëµëª… ìƒì„±
# ==========================================
# graph.py

# [1] ìƒë‹¨ importì— DB ì—°ê²° í•¨ìˆ˜ í™•ì¸
from database import get_db_connection

# [2] ë©”íƒ€ ë°ì´í„°(ìœ íš¨ í•„í„° ê°’) ê°€ì ¸ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜ ì¶”ê°€
def fetch_meta_filters():
    """
    DBì—ì„œ í˜„ì¬ ì¡´ì¬í•˜ëŠ” Season, Occasion, Accordì˜ ìœ íš¨í•œ ê°’ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    [ìˆ˜ì •] í…Œì´ë¸” ì´ë¦„ ì‹¤ì œ DB(ì¤„ì„ë§)ì— ë§ê²Œ ë³€ê²½
    """
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        
        # 1. Season (ê³„ì ˆ) -> tb_perfume_season_m (ì´ê±´ ì¤„ì„ë§ ì•„ë‹˜)
        cur.execute("SELECT DISTINCT season FROM tb_perfume_season_m WHERE season IS NOT NULL")
        seasons = [r[0] for r in cur.fetchall()]
        
        # 2. Occasion (ìƒí™©) -> [ìˆ˜ì •] tb_perfume_oca_m (ì¤„ì„ë§ ì ìš©!)
        cur.execute("SELECT DISTINCT occasion FROM tb_perfume_oca_m WHERE occasion IS NOT NULL")
        occasions = [r[0] for r in cur.fetchall()]
        
        # 3. Accord (í–¥ì¡°) -> tb_perfume_accord_m
        cur.execute("SELECT DISTINCT accord FROM tb_perfume_accord_m WHERE accord IS NOT NULL")
        accords = [r[0] for r in cur.fetchall()]
        
        conn.close()
        
        return (
            ", ".join([f"'{s}'" for s in seasons]),
            ", ".join([f"'{o}'" for o in occasions]),
            ", ".join([f"'{a}'" for a in accords])
        )
    except Exception as e:
        print(f"âš ï¸ Meta Filter Load Error: {e}")
        # DB ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ ë¦¬í„´ (ë´‡ì´ ì£½ì§€ ì•Šë„ë¡)
        return (
            "'Spring', 'Summer', 'Fall', 'Winter'",
            "'Daily', 'Formal', 'Date', 'Party'",
            "'Citrus', 'Woody', 'Floral', 'Musk'"
        )

# [3] researcher í•¨ìˆ˜ êµì²´
def researcher(state: State) -> State:
    try:
        query = state["user_query"]
        print(f"\nğŸ•µï¸ [Researcher] DB ë©”íƒ€ ë°ì´í„° ê¸°ë°˜ ì „ëµ ìˆ˜ë¦½: {query}", flush=True)

        # â˜… DBì—ì„œ ìœ íš¨í•œ í•„í„° ê°’ ì‹¤ì‹œê°„ ë¡œë”©
        valid_seasons, valid_occasions, valid_accords = fetch_meta_filters()

        prompt = f"""
        ë‹¹ì‹ ì€ ë³´ìœ í•œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì™„ë²½í•˜ê²Œ í™œìš©í•˜ëŠ” 'í¼í“¸ ë””ë ‰í„°'ì…ë‹ˆë‹¤.
        ì‚¬ìš©ì ìš”ì²­("{query}")ì„ ë¶„ì„í•´ **ê°€ì¥ ë§¤ë ¥ì ì¸ 3ê°€ì§€ ìŠ¤íƒ€ì¼ë§ ì „ëµ**ì„ ìˆ˜ë¦½í•˜ì„¸ìš”.
        
        === [1. ë³´ìœ  ë°ì´í„° ë§¤í•‘ (Data Mapping)] - â˜…í•µì‹¬â˜… ===
        ì‚¬ìš©ìì˜ ë§ì—ì„œ ì•„ë˜ **[í—ˆìš©ëœ ê°’ ëª©ë¡]**ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ê°€ ë‚˜ì˜¤ë©´ **ë°˜ë“œì‹œ `filters`ì— í¬í•¨**ì‹œí‚¤ì„¸ìš”.
        
        1. **Brand**: ë¸Œëœë“œëª… (ì˜ˆ: 'Chanel', 'Dior') -> `filters`
        2. **Gender**: ì„±ë³„ (ì˜ˆ: 'Feminine', 'Masculine') -> `filters`
        
        3. **Season (ê³„ì ˆ)**: 
           - **[í—ˆìš©ëœ ê°’]**: [{valid_seasons}]
           - ì‚¬ìš©ìê°€ "ì—¬ë¦„"ì´ë¼ê³  í•˜ë©´ ìœ„ ëª©ë¡ ì¤‘ 'Summer'ë¥¼ ì°¾ì•„ `{{'column': 'season', 'value': 'Summer'}}`ë¡œ ì„¤ì •.
           
        4. **Occasion (ìƒí™©)**: 
           - **[í—ˆìš©ëœ ê°’]**: [{valid_occasions}]
           - ì‚¬ìš©ìê°€ "ë°ì¼ë¦¬"ë¼ê³  í•˜ë©´ ìœ„ ëª©ë¡ ì¤‘ ë§¤ì¹­ë˜ëŠ” ê°’ì„ ì°¾ì•„ `filters`ì— ì„¤ì •.
           
        5. **Accord (í–¥ì¡°)**: 
           - **[í—ˆìš©ëœ ê°’]**: [{valid_accords}]
           - ì‚¬ìš©ìê°€ "ìƒí¼í•œ ì‹œíŠ¸ëŸ¬ìŠ¤"ë¼ê³  í•˜ë©´ ìœ„ ëª©ë¡ ì¤‘ 'Citrus'ë¥¼ ì°¾ì•„ `filters`ì— ì„¤ì •.

        === [2. ì‹œë‚˜ë¦¬ì˜¤ë³„ í–‰ë™ ì§€ì¹¨] ===
        **Type A. [ì´ë¯¸ì§€/ë¶„ìœ„ê¸°]** (ì˜ˆ: "ì‹œí¬í•œ", "í¬ê·¼í•œ")
        - ì „ëµ: DB í—ˆìš© ê°’ì— ì—†ëŠ” ì¶”ìƒì  í‘œí˜„ì€ `note_keywords`ì— ë„£ì–´ ë²¡í„° ê²€ìƒ‰.
        
        **Type B. [íŠ¹ì • ì¡°ê±´]** (ì˜ˆ: "ì—¬ë¦„ì— ë¿Œë¦´ ì‹œíŠ¸ëŸ¬ìŠ¤")
        - ì „ëµ: **DB í•„í„°ë§ ìš°ì„ !** (ìœ„ í—ˆìš©ëœ ê°’ ëª©ë¡ì— ì¡´ì¬í•œë‹¤ë©´ `filters` ì‚¬ìš©)
        
        **Type D. [ì„ ë¬¼/ì…ë¬¸]** (ì˜ˆ: "ì—¬ì¹œ ì„ ë¬¼")
        - ì „ëµ: `note_keywords`ì— "Soap", "Clean", "Light Floral" ë“± í˜¸ë¶ˆí˜¸ ì—†ëŠ” í‚¤ì›Œë“œ ìë™ ì¶”ê°€.

        === [3. ì „ëµ ìˆ˜ë¦½ í”„ë ˆì„ì›Œí¬ (3-Step Styling)] ===
        **Plan 1. [ë™ì¡° (Harmony)]**: "ì´ë¯¸ì§€ ì§ê´€ì  ë°˜ì˜"
        **Plan 2. [ë°˜ì „ (Gap)]**: "ì˜ì™¸ì˜ ë§¤ë ¥ í¬ì¸íŠ¸"
        **Plan 3. [ë³€í™” (Shift)]**: "ì…ì²´ì  ë°¸ëŸ°ìŠ¤"

        === [4. ì‘ì„± ê·œì¹™] ===
        1. `strategy_name`ì€ **"ê½ƒí–¥ê¸°", "ë¹„ëˆ„ ëƒ„ìƒˆ", "ì‚´ëƒ„ìƒˆ"** ë“± ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì§€ìœ¼ì„¸ìš”.
        2. ëª¨ë“  í•„í„° ê°’(`value`)ì€ ìœ„ **[í—ˆìš©ëœ ê°’]** ì¤‘ì—ì„œë§Œ ê³¨ë¼ì•¼ í•˜ë©°, ë°˜ë“œì‹œ **ì˜ì–´(English)**ì—¬ì•¼ í•©ë‹ˆë‹¤.
        
        ì‘ë‹µ(JSON) ì˜ˆì‹œ:
        {{
            "scenario_type": "Type B (Specific)",
            "plans": [
                {{
                    "priority": 1,
                    "strategy_name": "ì—¬ë¦„ í–‡ì‚´ ê°™ì€ ìƒí¼í•œ ì‹œíŠ¸ëŸ¬ìŠ¤",
                    "filters": [
                        {{"column": "season", "value": "Summer"}},  // [í—ˆìš©ëœ ê°’] ì¤‘ ì„ íƒ
                        {{"column": "accord", "value": "Citrus"}},  // [í—ˆìš©ëœ ê°’] ì¤‘ ì„ íƒ
                        {{"column": "gender", "value": "Unisex"}}
                    ],
                    "note_keywords": ["Fresh", "Lime"], 
                    "use_vector_search": true
                }}
            ]
        }}
        """
        
        msg = client.chat.completions.create(
            model=HIGH_PERFORMANCE_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        
        # ================= [ksu] Researcher í† í° ì§‘ê³„ =================
        in_tok = msg.usage.prompt_tokens
        out_tok = msg.usage.completion_tokens
        
        # ì´ì „ ë‹¨ê³„(Supervisor ë“±)ì—ì„œ ë„˜ì–´ì˜¨ í† í°ì— ë”í•˜ê¸°
        total_in = state.get("input_tokens", 0) + in_tok
        total_out = state.get("output_tokens", 0) + out_tok
        # ================= [ksu] Researcher í† í° ì§‘ê³„ =================

        parsed = safe_json_parse(msg.choices[0].message.content)
        plans = parsed.get("plans", []) if parsed else []
        scenario_type = parsed.get("scenario_type", "Unknown")
        
        print(f"   ğŸ’¡ ì„ íƒëœ ì‹œë‚˜ë¦¬ì˜¤: {scenario_type}", flush=True)
        
        search_logs = []
        final_result_text = ""
        
        for plan in plans:
            priority = plan.get('priority', '?')
            strategy = plan.get('strategy_name', f"Strategy-{priority}")
            
            print(f"   ğŸ‘‰ [Priority {priority}] ì‹¤í–‰: {strategy}", flush=True)
            
            current_filters = []
            
            for f in plan.get("filters", []):
                if not isinstance(f, dict): continue
                col = f.get('column')
                val = f.get('value')
                if not col or not val: continue
                
                # ë¸Œëœë“œ/í–¥ìˆ˜ëª… ì˜¤íƒ€ ë³´ì •
                if col in ['brand', 'perfume_name']:
                    corrected = search_exact_entity(val, col)
                    if corrected: f['value'] = corrected
                
                current_filters.append(f)
            
            notes = []
            if plan.get("use_vector_search"):
                notes.extend(search_notes_vector(query, top_k=3))
            
            for k in plan.get("note_keywords", []):
                notes.extend(search_notes_vector(k, top_k=2))
                
            if notes:
                current_filters.append({"column": "note", "value": list(set(notes))})
            
            # ê²€ìƒ‰ ì‹¤í–‰
            result_text = execute_precise_search(current_filters)
            
            if result_text:
                print(f"     âœ… ê²°ê³¼ í™•ë³´", flush=True)
                search_logs.append(f"ì „ëµ [{strategy}] ì„±ê³µ")
                final_result_text += f"\n=== [ì „ëµ: {strategy}] ===\n{result_text}\n"
            else:
                print(f"     âŒ ê²°ê³¼ ì—†ìŒ", flush=True)
                search_logs.append(f"ì „ëµ [{strategy}] ê²°ê³¼ ì—†ìŒ")
        
        if not final_result_text:
            final_result_text = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        return {
            "search_plans": plans,
            "search_logs": search_logs,
            "research_result": final_result_text,
            "route": "writer",
            "input_tokens": total_in,    # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
            "output_tokens": total_out   # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
        }
        
    except Exception:
        print("\nğŸš¨ [Researcher Error]", flush=True)
        traceback.print_exc()
        return {"research_result": "ì˜¤ë¥˜ ë°œìƒ", "route": "writer"}


# ==========================================
# 4. Writer (ê¸€ì“°ê¸°) - 1ì „ëµ 1í–¥ìˆ˜ & ì˜ë„ ì„¤ëª…
# ==========================================
# ì›ë³¸ ê·œì¹™
# 459 : - ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ë‹¤ë©´ ë°˜ë“œì‹œ ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìŒì„ ì•Œë¦¬ê³  ë‹¤ë¥¸ ê²€ìƒ‰ìš© ì¿¼ë¦¬ë¡œ ë§Œë“¤ìˆ˜ ìˆì„ë§Œí•œ ì§ˆë¬¸ì„ ë˜ì§ˆ ê²ƒ.
# 460 : - ì ˆëŒ€ë¡œ ì„ì˜ì˜ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•˜ì§€ ì•Šì„ ê²ƒ.

def writer(state: State) -> State:
    try:
        print("âœï¸ [Writer] ë‹µë³€ ì‘ì„±", flush=True)
        query = state["user_query"]
        result = state.get("research_result", "")
        
        prompt = f"""
        ë‹¹ì‹ ì€ í–¥ìˆ˜ë¥¼ ì˜ ëª¨ë¥´ëŠ” ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¸ìƒì—ì„œ ê°€ì¥ ì¹œì ˆí•œ í–¥ìˆ˜ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
        
        [ì‚¬ìš©ì ìš”ì²­]: "{query}"
        
        [ê²€ìƒ‰ëœ í–¥ìˆ˜ ë°ì´í„°]: 
        {result}
        
        [ì‘ì„± ê·œì¹™ - í•„ë…]
        0. **ê²€ìƒ‰ê²°ê³¼ì— ë”°ë¥¸ ì¶œë ¥**:
            - ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆë‹¤ë©´: ì•„ë˜ ê·œì¹™ë“¤ì„ ì—„ê²©íˆ ë”°ë¼ ì¶”ì²œí•  ê²ƒ.
            - ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ë‹¤ë©´:
                - ì‚¬ìš©ìê°€ í–¥ìˆ˜ ì¶”ì²œì„ ì›í•œ ê²½ìš°: "ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ì–´ì„œ ì¶”ì²œì´ ì–´ë µë‹¤"ê³  ì†”ì§íˆ ë§í•˜ê³ , ì·¨í–¥ì„ ë‹¤ì‹œ ë¬¼ì–´ë³¼ ê²ƒ.
                - ì‚¬ìš©ìê°€ 'ì•ˆë…•', 'ê³ ë§ˆì›Œ' ë“± **ë‹¨ìˆœ ëŒ€í™”(Small Talk)**ë¥¼ í•œ ê²½ìš°: **ì ˆëŒ€ DBë‚˜ ê²€ìƒ‰ ì–˜ê¸°ë¥¼ êº¼ë‚´ì§€ ë§ê³ ** ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•  ê²ƒ. (ì•µë¬´ìƒˆ ê¸ˆì§€)
        
        1. **[â˜…1ì „ëµ 1í–¥ìˆ˜ ì›ì¹™â˜…]**: 
            - ê²€ìƒ‰ ê²°ê³¼ì— ì—¬ëŸ¬ í–¥ìˆ˜ê°€ ìˆë”ë¼ë„, **ê° ì „ëµ(Strategy) ë‹¹ ê°€ì¥ ì í•©í•œ í–¥ìˆ˜ ë”± 1ê°œë§Œ** ì„ ì •í•˜ì„¸ìš”.
            - ê²°ê³¼ì ìœ¼ë¡œ ì´ 3ê°œì˜ í–¥ìˆ˜ë§Œ ì¶”ì²œë˜ì–´ì•¼ í•©ë‹ˆë‹¤. (ì¤‘ë³µ ì¶”ì²œ ê¸ˆì§€)
            - ë‹¨ ì¶œë ¥ì‹œì— ì „ëµë³„ë¡œ ë”± í•œê°œì”© ì¶”ì²œí•œë‹¤ëŠ” ë‚´ìš©ì„ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
        
        2. **ëª©ì°¨ ìŠ¤íƒ€ì¼ (ì „ëµ ì˜ë„ ê°•ì¡°)**: 
            - í˜•ì‹: **`## ë²ˆí˜¸. [ì „ëµì´ë¦„] ë¸Œëœë“œ - í–¥ìˆ˜ëª…`**
            - **[ì „ëµì´ë¦„]**ì—ëŠ” Researcherê°€ ì •í•œ ì „ëµëª…(ì˜ˆ: "ê²‰ì°¨ì†ë”° ë°˜ì „ ë§¤ë ¥")ì„ ê·¸ëŒ€ë¡œ ë„£ë˜ ì „ëµ: ë“±ì˜ ë”±ë”±í•œ í‘œí˜„ì€ ì œì™¸ì‹œí‚¤ê³  ì „ëµìœ¼ ì„¤ëª…ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
            - ì˜ˆì‹œ: `## 1. [ì°¨ê°€ìš´ ì²«ì¸ìƒ ì† ë”°ëœ»í•œ ë°˜ì „] Chanel - Coco Noir`
        
        3. **ì´ë¯¸ì§€ í•„ìˆ˜**: `![í–¥ìˆ˜ëª…](ì´ë¯¸ì§€ë§í¬)`
        
        4. **[â˜…ë§¤ìš° ì¤‘ìš”â˜…] ì„œì‹ ë° ê°•ì¡° ê·œì¹™**:
            - **í•­ëª© ì œëª©(Label)**: ë°˜ë“œì‹œ **`_` (ì–¸ë”ë°”)**ë¡œ ê°ì‹¸ì„¸ìš”. (íŒŒë€ìƒ‰ ì œëª©)
            - ì˜ˆ: `_ì–´ë–¤ í–¥ì¸ê°€ìš”?_`, `_ì¶”ì²œ ì´ìœ _`, `_ì •ë³´_`
            - **ë‚´ìš© ê°•ì¡°(Highlight)**: í•µì‹¬ ë‹¨ì–´ëŠ” **`**` (ë³„í‘œ 2ê°œ)**ë¡œ ê°ì‹¸ì„¸ìš”. (í•‘í¬ìƒ‰ ê°•ì¡°)
            - ì˜ˆ: `ì²˜ìŒì—” **ìƒí¼í•œ ê·¤ í–¥**ì´ ë‚˜ìš”.`
        
        5. **êµ¬ë¶„ì„ **: í–¥ìˆ˜ ì¶”ì²œ ì‚¬ì´ì— `---` ì‚½ì….
        
        6. **ì •ë³´ í‘œê¸°**: ë¸Œëœë“œ, ì´ë¦„, ì¶œì‹œë…„ë„ë§Œ ê¸°ì¬.
        
        7. **[â˜…í•„ìˆ˜â˜…] í–¥ ì„¤ëª… ë°©ì‹ (ìš©ì–´ ì ˆëŒ€ ê¸ˆì§€)**:
            - **[ì ˆëŒ€ ê¸ˆì§€]**: 'íƒ‘', 'ë¯¸ë“¤', 'ë² ì´ìŠ¤', 'ë…¸íŠ¸', 'ì–´ì½”ë“œ'ë¼ëŠ” ë‹¨ì–´ë‚˜ `(íƒ‘)`, `(ë¯¸ë“¤)` ê°™ì€ ê´„í˜¸ í‘œê¸°ë¥¼ **ì ˆëŒ€** ì“°ì§€ ë§ˆì„¸ìš”.
            - **[ì‘ì„±ë²•]**: ì‹œê°„ì˜ íë¦„ì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œë§Œ í‘œí˜„í•˜ì„¸ìš”.
            - **[ì˜ˆì™¸ìƒí™©]**:íƒ‘/ë¯¸ë“¤/ë² ì´ìŠ¤ì˜ ë…¸íŠ¸ê°€ ëª¨ë‘ ë™ì¼í•  ê²½ìš° ì „ì²´ì ìœ¼ë¡œ ~~ í–¥ì´ ì§€ì†ëœë‹¤ëŠ” ì‹ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
            - *Bad*: "ì²˜ìŒì—ëŠ” ë ˆëª¬ í–¥ì´ ë‚˜ìš”(íƒ‘)."
            - *Good*: "ì²˜ìŒì—ëŠ” **ë§‰ ì§  ë ˆëª¬ì¦™**ì²˜ëŸ¼ ìƒí¼í•˜ê²Œ ì‹œì‘í•´ìš”. ì‹œê°„ì´ ì§€ë‚˜ë©´..."
           
        8. **[í•µì‹¬] ì¶”ì²œ ë…¼ë¦¬ ì—°ê²° (Why?)**:
            - `_ì¶”ì²œ ì´ìœ _`ë¥¼ ì‘ì„±í•  ë•Œ, **"ì™œ ì´ ì „ëµ(ë°˜ì „/ì§ê´€ ë“±)ìœ¼ë¡œ ì´ í–¥ìˆ˜ë¥¼ ë½‘ì•˜ëŠ”ì§€"** ì„¤ëª…í•˜ì„¸ìš”.
            - ê³¼í•œ ë§ˆì¼€íŒ… ë¬¸êµ¬(ì˜ˆ: "ì •ì„", "ëíŒì™•", "ê°íˆ ì¶”ì²œ") ëŒ€ì‹  **ë‹´ë°±í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ** ì„¤ë“í•˜ì„¸ìš”.
            - *Bad*: "ì‹œí¬í•¨ì˜ ì •ì„ì´ë¼ ê°íˆ ì¶”ì²œë“œë ¤ìš”."
            - *Good*: "ê³ ê°ë‹˜ì´ **ì‹œí¬í•œ ì´ë¯¸ì§€**ë¥¼ ì›í•˜ì…¨ì£ ? ì´ í–¥ì€ **ë‹¨ë§› ì—†ì´ ê±´ì¡°í•œ ë‚˜ë¬´ í–¥**ì´ë¼ ê¹”ë”í•˜ê³  ë„ì‹œì ì¸ ëŠë‚Œì„ ì£¼ê¸°ì— ê°€ì¥ ì í•©í•´ìš”."

        9. **[ë§¤ìš° ì¤‘ìš”] ë¬˜ì‚¬ ë° ê°•ì¡° ê·œì¹™**:
            - **ì „ë¬¸ ìš©ì–´ ê¸ˆì§€**: ë…¸íŠ¸, ì–´ì½”ë“œ, íƒ‘/ë¯¸ë“¤/ë² ì´ìŠ¤ ë“±ì€ ì“°ì§€ ë§ˆì„¸ìš”.
            - **ì‰¬ìš´ ìš°ë¦¬ë§ ë²ˆì—­**: "ë¹„ì— ì –ì€ ë‚˜ë¬´", "í¬ê·¼í•œ ì´ë¶ˆ ëƒ„ìƒˆ"ì²˜ëŸ¼ ì˜¤ê°ì´ ëŠê»´ì§€ê²Œ ì“°ì„¸ìš”.
            - **â˜…í•µì‹¬ ê°•ì¡°(í•„ìˆ˜)â˜…**:
            - í–¥ì„ ë¬˜ì‚¬í•˜ëŠ” **í•µì‹¬ í‚¤ì›Œë“œ**ë‚˜ **ë¹„ìœ  í‘œí˜„**ì€ ë°˜ë“œì‹œ **êµµê²Œ(`**...**`)** ì²˜ë¦¬í•˜ì„¸ìš”.
            - ì˜ˆ: "ì²˜ìŒì—” **ìƒí¼í•œ ê·¤ê»ì§ˆ í–¥**ì´ ë‚˜ë‹¤ê°€, ê³§ **ë”°ëœ»í•œ í–¥ì‹ ë£Œ ì°¨**ì²˜ëŸ¼ ë³€í•´ìš”."
        [ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
        
        ì•ˆë…•í•˜ì„¸ìš”! ìš”ì²­í•˜ì‹  ì‹œí¬í•œ ëŠë‚Œì„ 3ê°€ì§€ ë¬´ë“œë¡œ í•´ì„í•´ë´¤ì–´ìš”.
        
        ## 1. [ë‚ ì¹´ë¡­ê³  ì •ëˆëœ ì‹œí¬] **Chanel - Sycomore**
        ![Sycomore](ë§í¬)
        
        - _ì–´ë–¤ í–¥ì¸ê°€ìš”?_: ì²˜ìŒì—” **ë¹„ ì˜¨ ë’¤ì˜ ìˆ²**ì²˜ëŸ¼ ì°¨ê°‘ê³  ìƒì¾Œí•´ìš”. ì‹œê°„ì´ ì§€ë‚˜ë©´ **ë§ˆë¥¸ ì¥ì‘** ê°™ì€ ë‚˜ë¬´ í–¥ì´ ì§„í•´ì§€ë©´ì„œ ë‹¨ì •í•˜ê²Œ ë§ˆë¬´ë¦¬ë¼ìš”.
        - _ì¶”ì²œ ì´ìœ _: êµ°ë”ë”ê¸° ì—†ì´ **ê¹”ë”í•˜ê³  ë“œë¼ì´í•œ í–¥**ì´ì—ìš”. **ì°¨ê°€ìš´ ë„ì‹œ ì´ë¯¸ì§€**ë¥¼ ê°€ì¥ ì§ê´€ì ìœ¼ë¡œ í‘œí˜„í•˜ê³  ì‹¶ì„ ë•Œ ì™„ë²½í•œ ì„ íƒì´ì—ìš”.
        - _ì •ë³´_: Chanel / Sycomore / 2008ë…„ ì¶œì‹œ
        
        ---
        
        ## 2. [ê²‰ì°¨ì†ë”° ë°˜ì „ ë§¤ë ¥] **Chanel - Coco Noir**
        ...
        """
        
        msg = client.chat.completions.create(
            model=HIGH_PERFORMANCE_MODEL, 
            messages=[{"role": "user", "content": prompt}]
        )
        
        # ================= [ksu] Writer í† í° ì§‘ê³„ =================
        in_tok = msg.usage.prompt_tokens
        out_tok = msg.usage.completion_tokens
        
        total_in = state.get("input_tokens", 0) + in_tok
        total_out = state.get("output_tokens", 0) + out_tok
        # ================= [ksu] Writer í† í° ì§‘ê³„ =================

        raw_content = msg.choices[0].message.content
        
        # [í›„ì²˜ë¦¬] ê°•ì¡° ê³µë°± ì œê±°
        fixed_content = re.sub(r'\*\*\s*(.*?)\s*\*\*', r'**\1**', raw_content)
        
        # ================= [ksu] í…ŒìŠ¤í„° ë¦¬í¬íŠ¸ ì €ì¥ ë¡œì§ =================
        test_info = state.get("test_info")
        if test_info:
            try:
                report_dir = "test_reports"
                os.makedirs(report_dir, exist_ok=True)
                
                today = datetime.now().strftime("%Y-%m-%d")
                report_file = os.path.join(report_dir, f"test_{today}.md")
                
                # ë¹„ìš© & ì‹œê°„ ê³„ì‚°
                cost = (total_in * 1.75 + total_out * 14.00) / 1_000_000
                
                start_ts = test_info.get("start_time", time.time()) # ì‹œì‘ ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
                duration = round(time.time() - start_ts, 2)         # ê±¸ë¦° ì‹œê°„ ê³„ì‚°
                
                # í—¤ë” ìƒì„± (11ê°œ ì»¬ëŸ¼ ë³µêµ¬)
                if not os.path.exists(report_file):
                    headers = [
                        "ì‹œê°„", "ëª©ì ", "ì‹œë‚˜ë¦¬ì˜¤", "í™˜ê²½", 
                        "ì…ë ¥", "ê¸°ëŒ€ê°’", "ì‹¤ì œì¶œë ¥(ìš”ì•½)", 
                        "ì†Œìš”ì‹œê°„(ì´ˆ)", "ë¹„ìš©($)", "í† í°(In/Out)", "ë¶„ì„/ë¹„ê³ "
                    ]
                    with open(report_file, "w", encoding="utf-8") as f:
                        f.write(f"# ğŸ§ª Chat Test Report ({today})\n\n")
                        f.write("| " + " | ".join(headers) + " |\n")
                        f.write("|" + "---|" * len(headers) + "\n")
                # í–‰ ì¶”ê°€
                now_time = datetime.now().strftime("%H:%M:%S")
                summary = fixed_content[:50].replace("\n", " ") + "..."
                row = [
                    now_time,
                    test_info['purpose'],
                    test_info['scenario'],
                    "Chat/GPT-5.2",
                    query,
                    test_info['expected'],
                    summary,
                    f"{duration}s",        # [ì¶”ê°€ë¨]
                    f"${round(cost, 6)}",
                    f"{total_in}/{total_out}",
                    ""                     # [ì¶”ê°€ë¨] ë¹„ê³ 
                ]
                with open(report_file, "a", encoding="utf-8") as f:
                    f.write("| " + " | ".join([str(x) for x in row]) + " |\n")
                    
                print(f"ğŸ“ [Test Report] ê¸°ë¡ ì™„ë£Œ", flush=True)
            except Exception as e:
                print(f"âš ï¸ [Report Error] {e}", flush=True)
        # ========================= [ksu] í…ŒìŠ¤í„° ë¦¬í¬íŠ¸ ì €ì¥ ë¡œì§ =========================

        return {"final_response": fixed_content,
                "input_tokens": total_in,   # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
                "output_tokens": total_out}  # [ksu] í† í° ì‚¬ìš©ëŸ‰ ëˆ„ì 
        
    except Exception:
        print("\nğŸš¨ [Writer Error]", flush=True)
        traceback.print_exc()
        return {"final_response": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}


# ==========================================
# Graph Build
# ==========================================
def build_graph():
    graph = StateGraph(State)
    
    graph.add_node("supervisor", supervisor)
    graph.add_node("interviewer", interviewer)
    graph.add_node("researcher", researcher)
    graph.add_node("writer", writer)
    
    graph.add_edge(START, "supervisor")
    
    def route_decision(state: State):
        return state["route"]
    
    graph.add_conditional_edges(
        "supervisor",
        route_decision,
        {"interviewer": "interviewer", "researcher": "researcher", "writer": "writer"}
    )
    
    graph.add_conditional_edges(
        "interviewer",
        route_decision,
        # {"researcher": "researcher", "end": END}
        {"researcher": "researcher", "writer": "writer", "end": END}
    )
    
    graph.add_edge("researcher", "writer")
    graph.add_edge("writer", END)
    
    # ë©”ëª¨ë¦¬ ì €ì¥ì†Œ(Checkpointer) ì ìš©
    memory = MemorySaver()
    
    return graph.compile(checkpointer=memory)