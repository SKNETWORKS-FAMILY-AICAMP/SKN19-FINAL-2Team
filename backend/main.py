import json
import traceback
from typing import Any, AsyncGenerator

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel # ğŸ‘ˆ Pydantic ëª¨ë¸ ì§ì ‘ ì •ì˜ë¥¼ ìœ„í•´ ì¶”ê°€

# graph.pyì—ì„œ ë¹Œë“œëœ ê·¸ë˜í”„ ê°€ì ¸ì˜¤ê¸°
from graph import build_graph

app = FastAPI(title="Perfume Chat Workflow")

origins = ["http://localhost:3000", "http://127.0.0.1:3000"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 1. ê·¸ë˜í”„ ë¹Œë“œ (MemorySaverê°€ graph.pyì— í¬í•¨ë˜ì–´ ìˆì–´ì•¼ í•¨)
workflow = build_graph()

# 2. ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜ (thread_id í•„ìˆ˜)
# schemas.pyë¥¼ ì•ˆ ì“°ê³  ì—¬ê¸°ì„œ ë°”ë¡œ ì •ì˜í•´ë„ ë©ë‹ˆë‹¤.
class ChatRequest(BaseModel):
    user_query: str
    thread_id: str

@app.get("/health")
def health() -> dict[str, Any]:
    return {"status": "ok"}

# 3. ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„° ìˆ˜ì • (ë¹„ë™ê¸° async ì ìš©)
async def stream_generator(user_query: str, thread_id: str) -> AsyncGenerator[str, None]:
    """LangGraph ì‹¤í–‰ ê²°ê³¼ë¥¼ SSE í¬ë§·ìœ¼ë¡œ ì‹¤ì‹œê°„ ì „ì†¡"""
    
    # LangGraphì— ì „ë‹¬í•  ì…ë ¥ê°’
    inputs = {
        "user_query": user_query,
        # 'messages'ë‚˜ 'history'ëŠ” MemorySaverê°€ ì•Œì•„ì„œ ê´€ë¦¬í•˜ë¯€ë¡œ ë„£ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
    }
    
    # ğŸ‘‡ [í•µì‹¬] ìŠ¤ë ˆë“œ IDë¥¼ ì„¤ì •ì— ë„£ì–´ì¤˜ì•¼ ê¸°ì–µì„ ì°¾ìŠµë‹ˆë‹¤.
    config = {"configurable": {"thread_id": thread_id}}

    try:
        # workflow.stream ëŒ€ì‹  .astream ì‚¬ìš© (ë¹„ë™ê¸°)
        async for event in workflow.astream(inputs, config=config):
            for node_name, state_update in event.items():

                # 1. Researcher ë¡œê·¸ ì „ì†¡ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                if node_name == "researcher" and "search_logs" in state_update:
                    logs = state_update["search_logs"]
                    if logs:
                        log_content = logs[-1]
                        log_data = json.dumps(
                            {
                                "type": "log",
                                "content": f"ğŸ” {log_content[:40]}...",
                            },
                            ensure_ascii=False,
                        )
                        yield f"data: {log_data}\n\n"

                # 2. Writer ë˜ëŠ” Interviewerì˜ ìµœì¢… í…ìŠ¤íŠ¸ ì „ì†¡
                if node_name in ["writer", "interviewer", "supervisor"]:
                    # final_responseê°€ ìˆìœ¼ë©´ ì •ë‹µìœ¼ë¡œ ì „ì†¡
                    if "final_response" in state_update:
                        final_res = state_update["final_response"]
                        data = json.dumps(
                            {"type": "answer", "content": final_res}, ensure_ascii=False
                        )
                        yield f"data: {data}\n\n"
                    
                    # Supervisorê°€ ì§ˆë¬¸ì´ ë¶€ì¡±í•´ì„œ ë°”ë¡œ ëë‚´ëŠ” ê²½ìš° ë“± ì²˜ë¦¬
                    elif "final_response" not in state_update and node_name == "interviewer":
                         pass 

    except Exception as e:
        print(f"\nğŸš¨ [Main Stream Error] ğŸš¨")
        traceback.print_exc()
        
        error_msg = json.dumps({"type": "error", "content": str(e)}, ensure_ascii=False)
        yield f"data: {error_msg}\n\n"


@app.post("/chat")
async def chat_stream(request: ChatRequest):
    # stream_generatorì— thread_id ì „ë‹¬
    return StreamingResponse(
        stream_generator(request.user_query, request.thread_id), 
        media_type="text/event-stream"
    )